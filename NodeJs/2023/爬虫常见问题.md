# 爬虫常见问题

1. 常用的爬虫库和框架

   - cheerio
   - playwright
   - Scrapy：一个强大的爬虫框架，提供了高度定制化和可扩展的爬取能力。它具有自动化的请求调度和处理、数据提取和存储等功能。
   - Splash：一个 JavaScript 渲染服务，可用于处理动态加载的网页。它可以与 Scrapy 和其他爬虫库集成，提供动态页面渲染的能力。
   - PyQuery：类似于 jQuery 语法的库，它基于解析库 lxml，可以方便地进行 HTML 解析和数据提取。
   - Pandas：用于数据处理和分析的库，可以将抓取到的数据进行清洗、转换和分析，方便进行后续的数据处理。

2. 处理反爬
   1. 伪装请求头，设置为常见的 `User-Agent`
   2. 代理 IP
   3. 处理验证码：`Tesseract`、云打码
   4. 分布式爬取：将爬虫任务分布到多个不同 IP 不同 cookie 的节点上
   5. 限制请求频率
   6. 使用 js 渲染引擎：如 Selenium 或 Splash，来模拟浏览器行为
3. 有效的策略限制爬虫速度
   1. 随机延时
   2. 自适应速度：响应快减少延时，响应慢增加延时
4. 遵守 robots.txt 规范
   1. `Crawl-delay`指定允许爬虫的爬取频率
5. 处理 403 Forbidden
   1. 更改 User-Agent
   2. 使用 Cookies
   3. 使用代理
   4. 每个请求添加等待时间
   5. 使用`requests`的`Session`对象处理重定向
6. 加快爬取速度
   1. 并发抓取
   2. 优化网络延迟：靠近目标服务器地理位置机器来运行
   3. 减少 DNS 查询：使用固定 IP 地址替代域名
   4. 使用 HTTP2 持久化连接
   5. 多台机器分布式爬虫
7. 监控爬虫
   1. 使用调度工具：Airflow、Luigi、Cron
   2. 日志：Elasticsearch、Logstash、Kibana
   3. 性能监控：Prometheus、Grafana
   4. 错误报告：Sentry
   5. 爬虫框架: Scrapy
8. 保护自己的网站不被爬取
   1. 使用`robots.txt`
   2. 检测`User-Agent`
   3. 使用`CAPTCHA`
   4. 检查请求速度，封禁 IP
   5. 使用 js ajax 加载内容
   6. 要求用户必须启用 Cookie 和 Session
9. 绕过 CAPTCHA
   1. 使用`OCR`：Tesseract
   2. 机器学习/深度学习
   3. 人工解决：有一些服务（如 Amazon Mechanical Turk 或各种 CAPTCHA 解决服务）提供人工解决 CAPTCHA 的服务，你可以将 CAPTCHA 发送给他们，他们会返回解决方案。
   4. 通过模拟人类行为（如随机化请求时间、模拟浏览器用户代理等）来避免触发 CAPTCHA。
   5. 直接请求 API：有些网站可能提供 API 服务，通过 API 请求数据不需要进行
      CAPTCHA 验证
