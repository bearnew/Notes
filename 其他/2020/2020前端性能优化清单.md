## 1.性能指标

![optimize index](https://github.com/bearnew/picture/blob/master/mardown/2020/%E5%85%B6%E4%BB%96/optimize_index.png?raw=true)

1. Time to Interactive (TTI)
   > 布局已经稳定、关键的 Web 字体可见、并且主线程已经空闲下来可以处理用户输入的时间点-基本上就是用户可以与 UI 交互的时间标记。这是了解用户必须经历多少等待才能毫无延迟地使用网站的关键指标。
2. First Input Delay (FID)
   > 从用户首次与网站进行交互到浏览器实际上能够响应该交互的时间。它很好地补充了 TTI 指标缺少的那部分：当用户实际与站点进行交互时会发生什么。一般仅用作 RUM 度量标准。有一个标准的 JavaScript 库[46]，用于在浏览器中测量 FID。
3. Largest Contentful Paint (LCP)
   > 这是在页面加载时间线中，标记已加载页面重要内容的时间点。假设页面中最重要的元素是在用户的视区中可见的最大元素。如果元素同时在可视区域的上方和下方渲染，只有可见部分被认为是相关的。目前在 Lighthouse 中，它是一个隐藏的指标，如果证明是有价值的，后续会推广。
4. Total Blocking Time (TBT)
   > 这是一种新的度量标准，有助于量化页面在变为可靠交互之前处于非交互状态的严重程度（也就是说，主线程至少在 5s 内没有运行超过 50ms 的任务（长任务））。度量的是从第一次绘画（FP）到交互时间（TTI）之间的时间长短（在这段时间内，主线程被阻塞足够长的时间而无法响应用户输入）。所以说，低的 TBT 是良好性能的体现。（感谢 Boris[49] Artem）
5. Cumulative Layout Shift[50]（CLS）
   > 该指标突出显示了用户访问网站时多久遇到一次意外的版式变化（重排）。它研究了不稳定因素及其对整体体验的影响。分数越低越好。
6. Speed Index
   > 度量页面内容可视化填充的速度，分数越低越好。速度指数分数是根据视觉填充的速度计算的，但它只是一个计算值。它对视口大小也很敏感，所以您需要定义一系列与您的目标用户是被相匹配的测试配置。请注意，随着 LCP 作为一种新度量标准的出现，它变得不那么重要了(谢谢，Boris, Artem!)。
7. CPU time spent
   > 这是显示主线程被阻塞的频率和时间的度量指标，受到浏览器绘制、渲染、加载和执行 JS 等动作的影响。高 CPU 响应时间是不稳定体验的明显指标，也就是说，这时候用户会体验到他们的操作和响应之间存在明显的滞后。使用 WebPagetest，您可以在“Chrome”选项卡上选择“Capture Dev Tools Timeline”[52]，以显示在使用 WebPagetest 的任何设备上运行时，主线程的被阻塞的具体细节。
8. Component-Level CPU Costs[53]
   > 类似上面的 CPU time spent，这个由 Stoyan Stefanov 提出的指标主要用于度量 JavaScript 对 CPU 的影响。这个指标的想法是使用每个组件的 CPU 指令计数来独立地了解每个组件中 Javascript 其对整体体验的影响。可以使用 Puppeteer 和 Chrome 来测量。
9. FrustrationIndex[54]（沮丧指数）
   > 上面介绍的许多指标解释了特定事件发生的时间，而 Tim Vereecket 提出的 FrustrationIndex 指标则着眼于各个里程碑之间的间隔，而不是独立地衡量它们。它衡量最终用户感知到的关键里程碑，例如 标题可见、第一个内容可见、视觉上准备就绪、页面准备就绪，并计算一个分数，指示加载页面时的沮丧程度。间隔时间越大，用户感到沮丧的可能性就越大。对于用户体验而言，这可能是一个很好的 KPI。Tim 发表了一篇 FrustrationIndex 介绍及其工作原理的详细帖子[55]。
10. Ad Weight Impact[56]
    > 如果您的站点依赖于广告产生的收入，那么跟踪与广告相关的代码大小是很有用的。Paddy Ganti 写了 1 个脚本[57]，可以构建了两个 URL(一个正常，一个阻止广告)，通过 WebPagetest 提示可以生成比较视频，并报告广告的增量。
11. Deviation metrics（偏差指标）
    > 正如 Wikipedia 工程师指出的那样，结果中存在多少差异的数据可以侧面反映您测量仪器的可靠性，以及应该对偏差和异常值给予多大的关注。较大的差异表明测试仪器的设置中需要进行调整。它还有助于了解某些页面是否更难以可靠地衡量，例如 “由于第三方脚本会导致重大变化”。跟踪浏览器版本也是一个好主意，这样可以方便地了解新版本的浏览器对性能的提高。
12. Custom metrics[58]
    > 自定义指标的定义来源于您的业务需求和客户体验。它要求您明确页面中重要的像素、关键脚本、必要的 CSS 和相关资源，并衡量它们对用户感知速度的影响。对于这一点，您可以监控 Hero Rendering Times[59]，或者使用 Performance API[60]，为对您的业务非常重要的事件标记特定的时间戳。此外，您还可以通过在测试结束时执行任意 JavaScript 来使用 WebPagetest 收集自定义指标。

## 2.资源优化

1. 使用`Brotli`进行纯文本压缩
   - 更高的压缩比
   - 但是耗费资源和时间，因此仅用于静态资源的压缩
2. 使用`webp`图片
3. 图像优化
   - `Pingo`
   - `SVGO`
4. 视频优化
   - H5 视频比 GIF 更轻、更小
   - 有损 GIF
5. 网络字体优化
   - 使用`preload`加载字体
   - 但应该放在 css 和 javascript 链接之后
6. 生成 2 个版本的 js 文件
   - `<script type="module"></script>`加载现代语法
   - `<script nomodule></script>`加载 ES5 语法
7. 工程化
   - `tree-shaking`, 构建结果只包含生产中用到的代码
   - `scope hoisting`，打平移除 webpack 作用域和加载相关的代码，转换为一个内联函数
   - 缩短 css 类名，如使用`css module`的`generateScopedName`函数`
   - `code-spliting`, 将代码拆分成按需加载的块
   - `preload-webpack-plugin`, 让浏览器使用 <linkrel="preload"> 或 <linkrel="prefetch"> 对分隔的代码“块”进行预加载
   - `@babel/plugin-transform-runtime`配置`helpers: true`使用帮助函数，避免每个包都去`polyfill`方法，减少代码量
8. 将昂贵的 js 操作转移到`web worker`中进行
9. 将繁重的 js 抽离到`service worker`中缓存
10. 将频繁执行的计算任务放到`WebAssembly`中进行
11. 流式渲染，首屏放入`Loading`和`head`中`preload`的`js`
12. `Service worker`缓存的是编译后的代码，`nginx`缓存主域名下的`Service worker`
13. `css modules`将首屏的`css`放入`head`中
14. 异步`import`，超过`1s`未`load`出来的加`loading`效果，`didMount`后`preload`需要异步加载的资源
15. 预加载图片，先显示缩略图，等帧动画请求完成再显示帧动画
16. 组件包，`Webview`预渲染
17. `require`中可以使用`import`的桥阶层，进行`tree shaking`
17. ssr中js分片初始化，图片下载完成后，阻塞import，等待GUI渲染完成
   - 任务分片: 入口文件使用`require`
   - 时间分片: 和 `React concurrent` 模式一样，使用`MessageChannel Api`
   - 模块懒初始化: `babel-plugin-lazy-import`

## 3.容错

1. 严格使用`TS`,`husky`提交限制
2. 服务端渲染`try catch`，`catch`里面执行`csr`流程
3. 服务端中间件监听`cpu`和内存情况，达到峰值降级走`csr`流程
4. 组件使用`Errobundary`和`try catch`
5. `Window`监听`error`，资源错误，降级`CDN`

## 4.工作流程

1. 设计规范，固定使用几种模板，通过传值完成业务需求，灰度验证样式差异性带来的数据影响（避免开发慢、UI 走查问题多）
2. 将统一的样式放到一个文件库中
3. 低代码平台，阿里的`imgCook`通过设计稿直接生成代码
4. `TS`规范使用
5. `React`和`Canvas`二合一，弹窗、逻辑复用，减少开发
6. 使用`Alloy Designer`高效还原`UI`
