# 爬虫实战总结

## 1.请求

1. ajax 接口 请求需要 vpn 代理

```js
import axios, { Axios, AxiosInstance } from "axios";
import { HttpProxyAgent } from "http-proxy-agent";

const agent = axios.create({
  timeout: 10000,
  httpAgent: new HttpProxyAgent(`http://${proxy.host}:${proxy.port}`),
  httpsAgent: new HttpProxyAgent(`http://${proxy.host}:${proxy.port}`),
});
```

2. `playwright`浏览器爬虫需要 vpn 代理

```js
import { Browser } from "playwright";
import playwright from "playwright-extra";
import stealth from "puppeteer-extra-plugin-stealth";
import UserAgent from "user-agents";

export const initBasePage = async () => {
  /** 【重要】指纹伪装 */
  await playwright.chromium.use(stealth());

  const kitList = [playwright.chromium, playwright.webkit, playwright.firefox];

  const kit = kitList[0];
  const browser: Browser = await kit.launch({
    /** 无头模式 */
    headless: false,
    proxy: {
      server: "http:127.0.0.1:15236",
    },
  });
  const userAgent = new UserAgent(/Chrome/);
  const context = await browser.newContext({
    ignoreHTTPSErrors: true,
    userAgent: userAgent.toString(), // 伪装user-agent
  });

  /** 定义一个全局脚本，禁用自动化测试相关的属性 */
  await context.addInitScript(() => {
    Object.defineProperty(navigator, "languages", {
      get: () => ["zh-CN", "zh", "en"],
    });
  });
  /** 【重要】新建一个playwright的实例，后续所有的页面操作都是基于这个实例 */
  const page = await context.newPage();
  return { context, page, browser };
};
```

3. 使用`curl`可支持更多的接口请求，包括 form-data

```js
/** 通过curl发送请求，在curl 后 增加 --insecure
 * --data-raw 改为 --data
 * 返回字符串
 */
export const execCurl = (
  curlString: string,
): Promise<{ dataString: any, status: number }> => {
  return new Promise((resolve, reject) => {
    exec(curlString, (error, stdout, stderr) => {
      if (error) {
        console.log(`execCurl error: ${error.message}`);
        reject({ error, stderr, status: 500 });
        return;
      }
      resolve({ dataString: stdout, status: 200 });
    });
  });
};

const { dataString } = await execCurl(`
    curl --insecure --location 'https://www.baidu.com/' \
    -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7' \
    -H 'Accept-Language: en,zh-CN;q=0.9,zh;q=0.8' \
    -H 'Cache-Control: no-cache' \
    -H 'Connection: keep-alive' \
    -H 'Cookie: BIDUPSID=2BDC935FE0C2F187122A3E235EB08033; PSTM=1683616098; BAIDUID=0639A08A66F2962C2DE97C98744916F4:FG=1; BAIDUID_BFESS=0639A08A66F2962C2DE97C98744916F4:FG=1; ZFY=VCAXYMrfJLmY7e:BkUqLQFRSa9zHJj4FxElUbfuKHWDE:C; baikeVisitId=fc0fd422-2832-4e44-9b95-5ddb38eef109; COOKIE_SESSION=0_0_1_1_0_2_1_0_1_1_1_0_0_0_0_0_0_0_1683616115%7C1%230_0_1683616115%7C1' \
    -H 'Pragma: no-cache' \
    -H 'Sec-Fetch-Dest: document' \
    -H 'Sec-Fetch-Mode: navigate' \
    -H 'Sec-Fetch-Site: none' \
    -H 'Sec-Fetch-User: ?1' \
    -H 'Upgrade-Insecure-Requests: 1' \
    -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36' \
    -H 'sec-ch-ua: "Google Chrome";v="119", "Chromium";v="119", "Not?A_Brand";v="24"' \
    -H 'sec-ch-ua-mobile: ?0' \
    -H 'sec-ch-ua-platform: "macOS"' \
    --data 'k_lang=en' \
    --compressed
`);
```

## 2.并发控制

- 每次最多同时发多少请求，控制 qps

## 3.请求重试

- 将成功的结果存入`redis`，失败计数，存在失败一直重试，重试次数限制

## 4.风控

1. 使用 webkit、firefox 爬取
2. 使用代理 IP 池
3. 解决 Recaptcha
   - https://github.com/danielgatis/puppeteer-recaptcha-solver
   - 语音识别:https://wit.ai/

## 5.数据存储

1. 数据存入 redis 中，达到阈值存入 mysql，执行完毕将 redis 中的值全部存入 mysql
2. 重试时需要将之前 redis 的值存入 mysql
